{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb36472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/meher/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Go up one level to reach OptiMindTune\n",
    "project_root = Path.cwd().resolve().parents[0]\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "# Add to sys.path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90124002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting OptiMind optimization benchmark\n",
      "INFO:core.data_manager:Loaded iris dataset: 150 samples, 4 features\n",
      "INFO:__main__:Loaded 1 datasets: ['iris']\n",
      "INFO:__main__:\n",
      "==================================================\n",
      "INFO:__main__:Starting optimization for iris dataset\n",
      "INFO:__main__:==================================================\n",
      "INFO:core.orchestrator:Initializing optimization for iris\n",
      "INFO:core.orchestrator:Starting iteration 1/2\n",
      "INFO:google.adk.models.google_llm:Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "You are an expert AI agent for AutoML. Given the dataset metadata and previous evaluation results, recommend 1-2 scikit-learn classification models and specific hyperparameter configurations to try next. If no previous results exist, suggest initial models and hyperparameters. Provide a brief reasoning for each recommendation. Respond with a JSON object: {\"recommendations\": [{\"model\": \"ModelName\", \"hyperparameters\": \"param1=value1, param2=value2 param3=value3\", \"reasoning\": \"Your reasoning\"}]}\n",
      "\n",
      "You are an agent. Your internal name is \"recommender\".\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"\\nDataset Metadata:\\nn_samples: 150\\nn_features: 4\\nn_classes: 3\\nclass_balance: {0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\\n\\nPrevious Results (if any):\\n[]\\n\\nSupported Models: RandomForestClassifier, LogisticRegression, SVC\\n\\nRespond with a JSON object: {\\\"recommendations\\\": [{\\\"model\\\": \\\"ModelName\\\", \\\"hyperparameters\\\": \\\"param1=value1, param2=value2\\\", \\\"reasoning\\\": \\\"Your reasoning\\\"}]}\\n\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "{\n",
      "  \"recommendations\": [\n",
      "    {\n",
      "      \"model\": \"RandomForestClassifier\",\n",
      "      \"hyperparameters\": \"n_estimators=100, max_depth=5, random_state=42\",\n",
      "      \"reasoning\": \"Random Forest is a robust ensemble method that often performs well on various datasets. Setting n_estimators to 100 provides a good balance between performance and computational cost. Limiting max_depth to 5 helps prevent overfitting on this relatively small dataset. Setting random_state ensures reproducibility.\"\n",
      "    },\n",
      "    {\n",
      "      \"model\": \"LogisticRegression\",\n",
      "      \"hyperparameters\": \"solver=liblinear, penalty=l1, C=1.0, random_state=42\",\n",
      "      \"reasoning\": \"Logistic Regression is a linear model suitable for multi-class classification. Using the 'liblinear' solver with L1 regularization (penalty='l1') can help with feature selection and prevent overfitting, particularly useful when there are a limited number of samples. C=1.0 is a reasonable starting point for the regularization strength. Setting random_state ensures reproducibility.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"{\\n  \\\"recommendations\\\": [\\n    {\\n      \\\"model\\\": \\\"RandomForestClassifier\\\",\\n      \\\"hyperparameters\\\": \\\"n_estimators=100, max_depth=5, random_state=42\\\",\\n      \\\"reasoning\\\": \\\"Random Forest is a robust ensemble method that often performs well on various datasets. Setting n_estimators to 100 provides a good balance between performance and computational cost. Limiting max_depth to 5 helps prevent overfitting on this relatively small dataset. Setting random_state ensures reproducibility.\\\"\\n    },\\n    {\\n      \\\"model\\\": \\\"LogisticRegression\\\",\\n      \\\"hyperparameters\\\": \\\"solver=liblinear, penalty=l1, C=1.0, random_state=42\\\",\\n      \\\"reasoning\\\": \\\"Logistic Regression is a linear model suitable for multi-class classification. Using the 'liblinear' solver with L1 regularization (penalty='l1') can help with feature selection and prevent overfitting, particularly useful when there are a limited number of samples. C=1.0 is a reasonable starting point for the regularization strength. Setting random_state ensures reproducibility.\\\"\\n    }\\n  ]\\n}\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.11261400362340415}],\"model_version\":\"gemini-2.0-flash\",\"usage_metadata\":{\"candidates_token_count\":246,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":246}],\"prompt_token_count\":346,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":346}],\"total_token_count\":592},\"automatic_function_calling_history\":[],\"parsed\":{\"recommendations\":[{\"model\":\"RandomForestClassifier\",\"hyperparameters\":\"n_estimators=100, max_depth=5, random_state=42\",\"reasoning\":\"Random Forest is a robust ensemble method that often performs well on various datasets. Setting n_estimators to 100 provides a good balance between performance and computational cost. Limiting max_depth to 5 helps prevent overfitting on this relatively small dataset. Setting random_state ensures reproducibility.\"},{\"model\":\"LogisticRegression\",\"hyperparameters\":\"solver=liblinear, penalty=l1, C=1.0, random_state=42\",\"reasoning\":\"Logistic Regression is a linear model suitable for multi-class classification. Using the 'liblinear' solver with L1 regularization (penalty='l1') can help with feature selection and prevent overfitting, particularly useful when there are a limited number of samples. C=1.0 is a reasonable starting point for the regularization strength. Setting random_state ensures reproducibility.\"}]}}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google.adk.models.google_llm:Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "You are an expert AI agent for AutoML. Given the dataset metadata and previous evaluation results, recommend 1-2 scikit-learn classification models and specific hyperparameter configurations to try next. If no previous results exist, suggest initial models and hyperparameters. Provide a brief reasoning for each recommendation. Respond with a JSON object: {\"recommendations\": [{\"model\": \"ModelName\", \"hyperparameters\": \"param1=value1, param2=value2 param3=value3\", \"reasoning\": \"Your reasoning\"}]}\n",
      "\n",
      "You are an agent. Your internal name is \"recommender\".\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"\\nDataset Metadata:\\nn_samples: 150\\nn_features: 4\\nn_classes: 3\\nclass_balance: {0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\\n\\nPrevious Results (if any):\\n[]\\n\\nSupported Models: RandomForestClassifier, LogisticRegression, SVC\\n\\nRespond with a JSON object: {\\\"recommendations\\\": [{\\\"model\\\": \\\"ModelName\\\", \\\"hyperparameters\\\": \\\"param1=value1, param2=value2\\\", \\\"reasoning\\\": \\\"Your reasoning\\\"}]}\\n\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"text\":\"{\\n  \\\"recommendations\\\": [\\n    {\\n      \\\"model\\\": \\\"RandomForestClassifier\\\",\\n      \\\"hyperparameters\\\": \\\"n_estimators=100, max_depth=5, random_state=42\\\",\\n      \\\"reasoning\\\": \\\"Random Forest is a robust ensemble method that often performs well on various datasets. Setting n_estimators to 100 provides a good balance between performance and computational cost. Limiting max_depth to 5 helps prevent overfitting on this relatively small dataset. Setting random_state ensures reproducibility.\\\"\\n    },\\n    {\\n      \\\"model\\\": \\\"LogisticRegression\\\",\\n      \\\"hyperparameters\\\": \\\"solver=liblinear, penalty=l1, C=1.0, random_state=42\\\",\\n      \\\"reasoning\\\": \\\"Logistic Regression is a linear model suitable for multi-class classification. Using the 'liblinear' solver with L1 regularization (penalty='l1') can help with feature selection and prevent overfitting, particularly useful when there are a limited number of samples. C=1.0 is a reasonable starting point for the regularization strength. Setting random_state ensures reproducibility.\\\"\\n    }\\n  ]\\n}\"}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"text\":\"\\nDataset Metadata:\\nn_samples: 150\\nn_features: 4\\nn_classes: 3\\nclass_balance: {0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\\n\\nPrevious Results (if any):\\n[]\\n\\nSupported Models: RandomForestClassifier, LogisticRegression, SVC\\n\\nRespond with a JSON object: {\\\"recommendations\\\": [{\\\"model\\\": \\\"ModelName\\\", \\\"hyperparameters\\\": \\\"param1=value1, param2=value2\\\", \\\"reasoning\\\": \\\"Your reasoning\\\"}]}\\n\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "{\n",
      "  \"recommendations\": [\n",
      "    {\n",
      "      \"model\": \"RandomForestClassifier\",\n",
      "      \"hyperparameters\": \"n_estimators=100, max_depth=5, random_state=42\",\n",
      "      \"reasoning\": \"Random Forest is a good initial choice due to its robustness and ability to handle non-linear relationships. n_estimators=100 provides a good balance between accuracy and computational cost. max_depth=5 helps prevent overfitting on this relatively small dataset. random_state ensures reproducibility.\"\n",
      "    },\n",
      "    {\n",
      "      \"model\": \"SVC\",\n",
      "      \"hyperparameters\": \"kernel=rbf, C=1.0, gamma=scale, random_state=42\",\n",
      "      \"reasoning\": \"SVC with an RBF kernel is a versatile model that can capture complex decision boundaries. C=1.0 is a reasonable starting point for the regularization parameter. gamma=scale automatically sets the gamma parameter based on the feature scale. random_state ensures reproducibility.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"{\\n  \\\"recommendations\\\": [\\n    {\\n      \\\"model\\\": \\\"RandomForestClassifier\\\",\\n      \\\"hyperparameters\\\": \\\"n_estimators=100, max_depth=5, random_state=42\\\",\\n      \\\"reasoning\\\": \\\"Random Forest is a good initial choice due to its robustness and ability to handle non-linear relationships. n_estimators=100 provides a good balance between accuracy and computational cost. max_depth=5 helps prevent overfitting on this relatively small dataset. random_state ensures reproducibility.\\\"\\n    },\\n    {\\n      \\\"model\\\": \\\"SVC\\\",\\n      \\\"hyperparameters\\\": \\\"kernel=rbf, C=1.0, gamma=scale, random_state=42\\\",\\n      \\\"reasoning\\\": \\\"SVC with an RBF kernel is a versatile model that can capture complex decision boundaries. C=1.0 is a reasonable starting point for the regularization parameter. gamma=scale automatically sets the gamma parameter based on the feature scale. random_state ensures reproducibility.\\\"\\n    }\\n  ]\\n}\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.062134841097844555}],\"model_version\":\"gemini-2.0-flash\",\"usage_metadata\":{\"candidates_token_count\":223,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":223}],\"prompt_token_count\":760,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":760}],\"total_token_count\":983},\"automatic_function_calling_history\":[],\"parsed\":{\"recommendations\":[{\"model\":\"RandomForestClassifier\",\"hyperparameters\":\"n_estimators=100, max_depth=5, random_state=42\",\"reasoning\":\"Random Forest is a good initial choice due to its robustness and ability to handle non-linear relationships. n_estimators=100 provides a good balance between accuracy and computational cost. max_depth=5 helps prevent overfitting on this relatively small dataset. random_state ensures reproducibility.\"},{\"model\":\"SVC\",\"hyperparameters\":\"kernel=rbf, C=1.0, gamma=scale, random_state=42\",\"reasoning\":\"SVC with an RBF kernel is a versatile model that can capture complex decision boundaries. C=1.0 is a reasonable starting point for the regularization parameter. gamma=scale automatically sets the gamma parameter based on the feature scale. random_state ensures reproducibility.\"}]}}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:core.orchestrator:Processing: RandomForestClassifier with n_estimators=100, max_depth=5, random_state=42\n",
      "INFO:core.orchestrator:Reasoning: Random Forest is a good initial choice due to its robustness and ability to handle non-linear relationships. n_estimators=100 provides a good balance between accuracy and computational cost. max_depth=5 helps prevent overfitting on this relatively small dataset. random_state ensures reproducibility.\n",
      "INFO:google.adk.models.google_llm:Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "You are an evaluation agent. Run the evaluate_model tool and return its results EXACTLY as received.\n",
      "            Do not modify the accuracy value. Return in format: {\"accuracy\": <value>}\n",
      "\n",
      "You are an agent. Your internal name is \"evaluation\".\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Evaluate RandomForestClassifier with n_estimators=100, max_depth=5, random_state=42\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "evaluate_model: {'model_name': {'type': <Type.STRING: 'STRING'>}, 'hyperparameters': {'type': <Type.STRING: 'STRING'>}} -> None\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "None\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "name: evaluate_model, args: {'hyperparameters': 'n_estimators=100, max_depth=5, random_state=42', 'model_name': 'RandomForestClassifier'}\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{\"hyperparameters\":\"n_estimators=100, max_depth=5, random_state=42\",\"model_name\":\"RandomForestClassifier\"},\"name\":\"evaluate_model\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.0003049277490185153}],\"model_version\":\"gemini-2.0-flash\",\"usage_metadata\":{\"candidates_token_count\":31,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":31}],\"prompt_token_count\":104,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":104}],\"total_token_count\":135},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:agents.evaluation.agent:Model RandomForestClassifier achieved accuracy: 0.9667\n",
      "INFO:google.adk.models.google_llm:Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "You are an evaluation agent. Run the evaluate_model tool and return its results EXACTLY as received.\n",
      "            Do not modify the accuracy value. Return in format: {\"accuracy\": <value>}\n",
      "\n",
      "You are an agent. Your internal name is \"evaluation\".\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Evaluate RandomForestClassifier with n_estimators=100, max_depth=5, random_state=42\"}],\"role\":\"user\"}\n",
      "{\"parts\":[{\"function_call\":{\"args\":{\"hyperparameters\":\"n_estimators=100, max_depth=5, random_state=42\",\"model_name\":\"RandomForestClassifier\"},\"name\":\"evaluate_model\"}}],\"role\":\"model\"}\n",
      "{\"parts\":[{\"function_response\":{\"name\":\"evaluate_model\",\"response\":{\"accuracy\":0.9666666666666668}}}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "evaluate_model: {'model_name': {'type': <Type.STRING: 'STRING'>}, 'hyperparameters': {'type': <Type.STRING: 'STRING'>}} -> None\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Response:\n",
      "-----------------------------------------------------------\n",
      "Text:\n",
      "{\"accuracy\": 0.96666666666666679}\n",
      "-----------------------------------------------------------\n",
      "Function calls:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Raw response:\n",
      "{\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"{\\\"accuracy\\\": 0.96666666666666679}\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"avg_logprobs\":-0.00015699302700037757}],\"model_version\":\"gemini-2.0-flash\",\"usage_metadata\":{\"candidates_token_count\":24,\"candidates_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":24}],\"prompt_token_count\":140,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":140}],\"total_token_count\":164},\"automatic_function_calling_history\":[]}\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:core.orchestrator:Evaluation result: {'accuracy': 0.9666666666666668, 'success': True}\n",
      "INFO:google.adk.models.google_llm:Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False\n",
      "INFO:google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "You are a decision agent. Given a model name, hyperparameters, accuracy, and previous results, decide whether to accept the model or recommend new ones. Respond with a JSON object: {\"accuracy\": float, \"accept\": boolean, \"reasoning\": \"Your reasoning\"}\n",
      "\n",
      "You are an agent. Your internal name is \"decision\".\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Decide whether to accept RandomForestClassifier with accuracy 0.9667.\\nPrevious results: []\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 84\u001b[0m\n\u001b[1;32m     81\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritical error in main execution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43morchestrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     optimization_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Store results\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune/core/orchestrator.py:72\u001b[0m, in \u001b[0;36mOptimizationOrchestrator.optimize_dataset\u001b[0;34m(self, dataset_name, X, y, timestamp)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Process recommendations\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m best_iteration_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_recommendations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecommendations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msessions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Update best model if improved\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_iteration_result \u001b[38;5;129;01mand\u001b[39;00m best_iteration_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m best_accuracy:\n",
      "File \u001b[0;32m~/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune/core/orchestrator.py:167\u001b[0m, in \u001b[0;36mOptimizationOrchestrator._process_recommendations\u001b[0;34m(self, recommendations, runners, sessions, dataset_name, iteration, timestamp)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Make decision\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_decision\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msessions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecommender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunners\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision \u001b[38;5;129;01mand\u001b[39;00m decision\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    173\u001b[0m     current_accuracy \u001b[38;5;241m=\u001b[39m eval_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune/core/orchestrator.py:228\u001b[0m, in \u001b[0;36mOptimizationOrchestrator._make_decision\u001b[0;34m(self, recommendation, eval_result, previous_results, runner, dataset_name, iteration, timestamp)\u001b[0m\n\u001b[1;32m    224\u001b[0m         decision_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mDecide whether to accept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecommendation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124mPrevious results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(previous_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         message \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mContent(role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, parts\u001b[38;5;241m=\u001b[39m[types\u001b[38;5;241m.\u001b[39mPart(text\u001b[38;5;241m=\u001b[39mdecision_input)])\n\u001b[0;32m--> 228\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdec_session_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event:\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune/core/agent_runner.py:55\u001b[0m, in \u001b[0;36mAgentRunner.run_agent\u001b[0;34m(self, runner, message, session_id)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Execute with rate limiting and retries\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_execute_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent returned no final response for session \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune/utils/rate_limiter.py:56\u001b[0m, in \u001b[0;36mRateLimitHandler.with_retries\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_if_needed()\n\u001b[1;32m     55\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 56\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Personal Projects/OptiMindTune_1/OptiMindTune/core/agent_runner.py:41\u001b[0m, in \u001b[0;36mAgentRunner.run_agent.<locals>._execute_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Internal function to execute the agent.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     42\u001b[0m         user_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muser_id,\n\u001b[1;32m     43\u001b[0m         session_id\u001b[38;5;241m=\u001b[39msession_id,\n\u001b[1;32m     44\u001b[0m         new_message\u001b[38;5;241m=\u001b[39mmessage\n\u001b[1;32m     45\u001b[0m     ):\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mis_final_response():\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m event\n",
      "File \u001b[0;32m~/miniforge3/envs/opti_mind_tune/lib/python3.10/site-packages/google/adk/runners.py:147\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, user_id, session_id, new_message, run_config)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# consumes and re-yield the events from background thread.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m   event \u001b[38;5;241m=\u001b[39m \u001b[43mevent_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/opti_mind_tune/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/opti_mind_tune/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "OptiMind: AI-Powered Model Optimization System\n",
    "Main entry point for the optimization benchmark.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from core.orchestrator import OptimizationOrchestrator\n",
    "from core.data_manager import DatasetManager\n",
    "from core.results_manager import ResultsManager\n",
    "from config import OptiMindConfig\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        load_dotenv(override=True)\n",
    "        # Initialize configuration\n",
    "        config = OptiMindConfig()\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Initialize managers\n",
    "        data_manager = DatasetManager()\n",
    "        results_manager = ResultsManager(config.logs_dir, config.csv_dir, timestamp)\n",
    "        orchestrator = OptimizationOrchestrator(config, results_manager)\n",
    "        \n",
    "        logger.info(\"Starting OptiMind optimization benchmark\")\n",
    "        \n",
    "        # Load datasets\n",
    "        datasets = data_manager.load_datasets(\"iris\")\n",
    "        logger.info(f\"Loaded {len(datasets)} datasets: {list(datasets.keys())}\")\n",
    "        \n",
    "        # Run optimization for each dataset\n",
    "        benchmark_results = {}\n",
    "        \n",
    "        for dataset_name, (X, y) in datasets.items():\n",
    "            logger.info(f\"\\n{'='*50}\")\n",
    "            logger.info(f\"Starting optimization for {dataset_name} dataset\")\n",
    "            logger.info(f\"{'='*50}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = orchestrator.optimize_dataset(dataset_name, X, y, timestamp)\n",
    "                optimization_time = time.time() - start_time\n",
    "                \n",
    "                # Store results\n",
    "                benchmark_results[dataset_name] = {\n",
    "                    **result,\n",
    "                    \"optimization_time\": optimization_time,\n",
    "                    \"iterations_per_second\": result[\"total_iterations\"] / optimization_time\n",
    "                }\n",
    "                \n",
    "                logger.info(f\"Completed {dataset_name} optimization in {optimization_time:.2f}s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to optimize {dataset_name}: {e}\")\n",
    "                benchmark_results[dataset_name] = {\n",
    "                    \"error\": str(e),\n",
    "                    \"optimization_time\": time.time() - start_time\n",
    "                }\n",
    "        \n",
    "        # Save final results\n",
    "        results_manager.save_benchmark_summary(benchmark_results)\n",
    "        results_manager.print_summary(benchmark_results)\n",
    "        \n",
    "        logger.info(\"OptiMind benchmark completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Critical error in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b09bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opti_mind_tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
